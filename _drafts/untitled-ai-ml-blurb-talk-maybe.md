---
layout: post
title: Untitled AI ML Blurb Talk Maybe
---

“Artificial Intelligence”, or just “AI” has become synonymous with all kinds of adaptive, interactive, creative, responsive, or ‘intelligent’ machine process over the past few years, such as chatbots from companies Google and OpenAI; or image (and even video) generation tools like DALL-E and Sora; however, this current zeitgeist belies the fact that ‘Machine Intelligence’ has been accelerating business and industrial automation since before the modern ‘computer’ existed. 

Even the first well documented counting machines such as Charles Babbages ‘Difference Engine’ from the 1820s can be considered on this continuum of AI; taking small tasks, repeating them, and adapting the repetitions to the inputs and results to ‘generate’ new outputs. For the Difference Engine, these inputs and outputs were the components of polynomial functions, to serve engineering, science and navigational workloads, previously generated by highly specialised and educated humans at a pace that would be considered glacial today.

But this would generally be considered ‘classical computation’; following repeated instructions but potentially with changing or looping data, and was the basis of the computing and eventually internet revolutions from Alan Turnings Enigma-targeting ‘bombe’ at Bletchley Park during World War II, through the explosion of custom ‘computers’ in the 50’s and 60’s, arguably culminating in the Apollo Guidance Computer taking mankind to the moon (Under navy eventually-Rear-Admiral Grace Hopper’s programming), eventually to the relative standardisation of the 70’s with Steves Wozniak and Jobs’ reveal of the Apple I and IBM’s coalescing around the x86 architecture series of chips that continues to this day. 

Computers got faster and had more memory and more peripherals, went to the moon and built virtual dungeons, eventually grew radios and batteries and shrunk everything else so now the power that we carry around in our pockets to doomscroll on Tiktok is billions of times more powerful than those earliest “computers”. 

This exponential, almost unstoppable growth in computing power enabled mathematicians, computer scientists, and even neuroscientists to try programming styles that Babbage (and not to elide Ada Lovelace, technically one of the first ‘programmers’) would have considered at best wasteful, and at worst insane. 

In fact, Alan Turning, along with his friend and peer Christopher Strachey, could be considered to have written the first “Generative AI” tool, a Love-Letter generator, that uses simple templates of Noun, Adjective, Verbs, Adverbs, etc in sequences that they knew as being ‘the right shape’ for human prose, and then generated random numbers to pick from ‘wordlists’ of those Nouns, Adjectives, Verbs and Adverbs etc.

This Love Letter generator is instructive to us, because the same principals apply to modern text “AI” tools like ChatGPT or Microsoft CoPilot; except those ‘templates’ and ‘wordlists’, instead of being hand-crafted by abstract-thinking humans, are instead ‘learned’ by looking at existing text input, and learning the structures, relationships, and ‘templates’ between and across words and sentences. The further back in a sentence or piece of text the AI is able to look, the longer it’s “Context Window”; the most versions of templates and lengths of wordlists are analogous to what modern LLMs would term ‘parameters’.

So the basic mechanisms of todays advanced ‘AI’ tools were already present at the ‘dawn’ of the information age; what changed was our computational power to ‘test’ trillions and trillions of scenarios and permutations, and iteratively improve our ability to generate and assess those permutations.

Looking at today’s hallucinating chatbots and Turing’s stochastic love letters, it would be natural to assume that no one has really made any legitimate use out of these tools and techniques, but this couldn’t be further from the truth, because between these probabilistic bookends of the information age, a whole world of Machine Learning grew and evolved between, coming more from the worlds of statistics and engineering than from literature and linguistics.

Computer Programming, like Lovelace’s polynomials, Turing’s bombe and the Hopper’s Apollo Guidance Computer, followed fixed rules and sequences

*THIS IS WHERE YOU GAVE UP*